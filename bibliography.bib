%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%		~~~~ Bibliography ~~~~
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Methods to get the information:
%       - Use the DOI of an article with doi2bib.org
%       - Use Google scholar to get .bib citations




@article{tibshiraniRegressionShrinkageSelection1996,
	title = {Regression Shrinkage and Selection via the Lasso},
	volume = {58},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2346178},
	abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
	pages = {267--288},
	number = {1},
	journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Tibshirani, Robert},
	urldate = {2024-10-01},
	date = {1996},
	note = {Publisher: [Royal Statistical Society, Oxford University Press]},
	file = {JSTOR Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\P4T83J23\\Tibshirani - 1996 - Regression Shrinkage and Selection via the Lasso.pdf:application/pdf},
}



@article{zouRegularizationVariableSelection2005,
author = {Zou, Hui and Hastie, Trevor},
year = {2005},
month = {04},
pages = {301 - 320},
title = {Zou H, Hastie T. Regularization and variable selection via the elastic net. J R Statist Soc B. 2005;67(2):301-20},
volume = {67},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
doi = {10.1111/j.1467-9868.2005.00503.x}
}

@article{piironenProjectiveInferenceHighdimensional2020,
	title = {Projective Inference in High-dimensional Problems: Prediction and Feature Selection},
	volume = {14},
	issn = {1935-7524},
	url = {http://arxiv.org/abs/1810.02406},
	doi = {10.1214/20-EJS1711},
	shorttitle = {Projective Inference in High-dimensional Problems},
	abstract = {This paper discusses predictive inference and feature selection for generalized linear models with scarce but high-dimensional data. We argue that in many cases one can beneﬁt from a decision theoretically justiﬁed two-stage approach: ﬁrst, construct a possibly non-sparse model that predicts well, and then ﬁnd a minimal subset of features that characterize the predictions. The model built in the ﬁrst step is referred to as the reference model and the operation during the latter step as predictive projection. The key characteristic of this approach is that it ﬁnds an excellent tradeoff between sparsity and predictive accuracy, and the gain comes from utilizing all available information including prior and that coming from the left out features. We review several methods that follow this principle and provide novel methodological contributions. We present a new projection technique that uniﬁes two existing techniques and is both accurate and fast to compute. We also propose a way of evaluating the feature selection process using fast leave-one-out cross-validation that allows for easy and intuitive model size selection. Furthermore, we prove a theorem that helps to understand the conditions under which the projective approach could be beneﬁcial. The beneﬁts are illustrated via several simulated and real world examples.},
	number = {1},
	journaltitle = {Electronic Journal of Statistics},
	shortjournal = {Electron. J. Statist.},
	author = {Piironen, Juho and Paasiniemi, Markus and Vehtari, Aki},
	urldate = {2024-09-21},
	date = {2020-01-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1810.02406 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:C\:\\Users\\wzp\\Zotero\\storage\\IA25K4R2\\Piironen et al. - 2020 - Projective Inference in High-dimensional Problems Prediction and Feature Selection.pdf:application/pdf},
}


@article{babyakWhatYouSee2004,
	title = {What You See May Not Be What You Get: A Brief, Nontechnical Introduction to Overfitting in Regression-Type Models},
	volume = {66},
	doi = {10.1097/01.psy.0000127692.23278.a9},
	shorttitle = {What You See May Not Be What You Get},
	abstract = {Objective: 
Statistical models, such as linear or logistic regression or survival analysis, are frequently used as a means to answer scientific questions in psychosomatic research. Many who use these techniques, however, apparently fail to appreciate fully the problem of overfitting, ie, capitalizing on the idiosyncrasies of the sample at hand. Overfitted models will fail to replicate in future samples, thus creating considerable uncertainty about the scientific merit of the finding. The present article is a nontechnical discussion of the concept of overfitting and is intended to be accessible to readers with varying levels of statistical expertise. The notion of overfitting is presented in terms of asking too much from the available data. Given a certain number of observations in a data set, there is an upper limit to the complexity of the model that can be derived with any acceptable degree of uncertainty. Complexity arises as a function of the number of degrees of freedom expended (the number of predictors including complex terms such as interactions and nonlinear terms) against the same data set during any stage of the data analysis. Theoretical and empirical evidence--with a special focus on the results of computer simulation studies--is presented to demonstrate the practical consequences of overfitting with respect to scientific inference. Three common practices--automated variable selection, pretesting of candidate predictors, and dichotomization of continuous variables--are shown to pose a considerable risk for spurious findings in models. The dilemma between overfitting and exploring candidate confounders is also discussed. Alternative means of guarding against overfitting are discussed, including variable aggregation and the fixing of coefficients a priori. Techniques that account and correct for complexity, including shrinkage and penalization, also are introduced.},
	pages = {411--21},
	journaltitle = {Psychosomatic medicine},
	shortjournal = {Psychosomatic medicine},
	author = {Babyak, Michael},
	date = {2004-05-01},
}


@article{hoerlRidgeRegressionBiased2000,
	title = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
	volume = {42},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1271436},
	doi = {10.2307/1271436},
	shorttitle = {Ridge Regression},
	abstract = {In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X′X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X′X to obtain biased estimates with smaller mean square error.},
	pages = {80--86},
	number = {1},
	journaltitle = {Technometrics},
	author = {Hoerl, Arthur E. and Kennard, Robert W.},
	urldate = {2024-12-14},
	date = {2000},
	note = {Publisher: [Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]},
	file = {JSTOR Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\SC6C4Q4K\\Hoerl and Kennard - 2000 - Ridge Regression Biased Estimation for Nonorthogonal Problems.pdf:application/pdf},
}


@article{hsiangBayesianViewRidge1975,
	title = {A Bayesian View on Ridge Regression},
	volume = {24},
	issn = {0039-0526},
	url = {https://www.jstor.org/stable/2987923},
	doi = {10.2307/2987923},
	pages = {267--268},
	number = {4},
	journaltitle = {Journal of the Royal Statistical Society. Series D (The Statistician)},
	author = {Hsiang, T. C.},
	urldate = {2024-10-06},
	date = {1975},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	file = {JSTOR Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\ZF5HT3N4\\Hsiang - 1975 - A Bayesian View on Ridge Regression.pdf:application/pdf},
}

@article{parkBayesianLasso2008,
author = {Park, Trevor and Casella, George},
year = {2008},
month = {02},
pages = {681-686},
title = {The Bayesian Lasso},
volume = {103},
journal = {Journal of the American Statistical Association},
doi = {10.2307/27640090}
}

@article{carvalhoHorseshoeEstimatorSparse2010,
	title = {The horseshoe estimator for sparse signals},
	volume = {97},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/25734098},
	abstract = {This paper proposes a new approach to sparsity, called the horseshoe estimator, which arises from a prior based on multivariate-normal scale mixtures. We describe the estimator's advantages over existing approaches, including its robustness, adaptivity to different sparsity patterns and analytical tractability. We prove two theorems: one that characterizes the horseshoe estimator's tail robustness and the other that demonstrates a super-efficient rate of convergence to the correct estimate of the sampling density in sparse situations. Finally, using both real and simulated data, we show that the horseshoe estimator corresponds quite closely to the answers obtained by Bayesian model averaging under a point-mass mixture prior.},
	pages = {465--480},
	number = {2},
	journaltitle = {Biometrika},
	author = {Carvalho, Carlos M. and Polson, Nicholas G. and Scott, James G.},
	urldate = {2024-10-06},
	date = {2010},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	file = {JSTOR Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\U7ZFS77S\\Carvalho et al. - 2010 - The horseshoe estimator for sparse signals.pdf:application/pdf},
}


@article{georgeVariableSelectionGibbs1993,
author = {George, Edward and McCulloch, Robert},
year = {1993},
month = {09},
pages = {881-889},
title = {Variable Selection Via Gibbs Sampling},
volume = {88},
journal = {Journal of The American Statistical Association - J AMER STATIST ASSN},
doi = {10.1080/01621459.1993.10476353}
}


@article{mitchellBayesianVariableSelection1988,
	title = {Bayesian Variable Selection in Linear Regression},
	volume = {83},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2290129},
	doi = {10.2307/2290129},
	abstract = {This article is concerned with the selection of subsets of predictor variables in a linear regression model for the prediction of a dependent variable. It is based on a Bayesian approach, intended to be as objective as possible. A probability distribution is first assigned to the dependent variable through the specification of a family of prior distributions for the unknown parameters in the regression model. The method is not fully Bayesian, however, because the ultimate choice of prior distribution from this family is affected by the data. It is assumed that the predictors represent distinct observables; the corresponding regression coefficients are assigned independent prior distributions. For each regression coefficient subject to deletion from the model, the prior distribution is a mixture of a point mass at 0 and a diffuse uniform distribution elsewhere, that is, a "spike and slab" distribution. The random error component is assigned a normal distribution with mean 0 and standard deviation σ, where ln(σ) has a locally uniform noninformative prior distribution. The appropriate posterior probabilities are derived for each submodel. If the regression coefficients have identical priors, the posterior distribution depends only on the data and the parameter γ, which is the height of the spike divided by the height of the slab for the common prior distribution. This parameter is not assigned a probability distribution; instead, it is considered a parameter that indexes the members of a class of Bayesian methods. Graphical methods are proposed as informal guides for choosing γ, assessing the complexity of the response function and the strength of the individual predictor variables, and assessing the degree of uncertainty about the best submodel. The following plots against γ are suggested: (a) posterior probability that a particular regression coefficient is 0; (b) posterior expected number of terms in the model; (c) posterior entropy of the submodel distribution; (d) posterior predictive error; and (e) posterior probability of goodness of fit. Plots (d) and (e) are suggested as ways to choose γ. The predictive error is determined using a Bayesian cross-validation approach that generates a predictive density for each observation, given all of the data except that observation, that is, a type of "leave one out" approach. The goodness-of-fit measure is the sum of the posterior probabilities of all submodels that pass a standard F test for goodness of fit relative to the full model, at a specified level of significance. The dependence of the results on the scaling of the variables is discussed, and some ways to choose the scaling constants are suggested. Examples based on a large data set arising from an energy-conservation study are given to demonstrate the application of the methods.},
	pages = {1023--1032},
	number = {404},
	journaltitle = {Journal of the American Statistical Association},
	author = {Mitchell, T. J. and Beauchamp, J. J.},
	urldate = {2024-12-21},
	date = {1988},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	file = {JSTOR Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\VHS9CZNV\\Mitchell and Beauchamp - 1988 - Bayesian Variable Selection in Linear Regression.pdf:application/pdf},
}



@article{barbieriOptimalPredictiveModel2004,
	title = {Optimal predictive model selection},
	volume = {32},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-32/issue-3/Optimal-predictive-model-selection/10.1214/009053604000000238.full},
	doi = {10.1214/009053604000000238},
	abstract = {Often the goal of model selection is to choose a model for future prediction, and it is natural to measure the accuracy of a future prediction by squared error loss. Under the Bayesian approach, it is commonly perceived that the optimal predictive model is the model with highest posterior probability, but this is not necessarily the case. In this paper we show that, for selection among normal linear models, the optimal predictive model is often the median probability model, which is defined as the model consisting of those variables which have overall posterior probability greater than or equal to 1/2 of being in a model. The median probability model often differs from the highest probability model.},
	pages = {870--897},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Barbieri, Maria Maddalena and Berger, James O.},
	urldate = {2024-10-02},
	date = {2004-06},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62F15, Variable selection, 62C10, Bayesian linear models, predictive distribution, squared error loss},
	file = {Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\2JJ53W6Z\\Barbieri and Berger - 2004 - Optimal predictive model selection.pdf:application/pdf},
}


@article{vanerpShrinkagePriorsBayesian2019,
	title = {Shrinkage priors for Bayesian penalized regression},
	volume = {89},
	issn = {0022-2496},
	url = {https://www.sciencedirect.com/science/article/pii/S0022249618300567},
	doi = {10.1016/j.jmp.2018.12.004},
	abstract = {In linear regression problems with many predictors, penalized regression techniques are often used to guard against overfitting and to select variables relevant for predicting an outcome variable. Recently, Bayesian penalization is becoming increasingly popular in which the prior distribution performs a function similar to that of the penalty term in classical penalization. Specifically, the so-called shrinkage priors in Bayesian penalization aim to shrink small effects to zero while maintaining true large effects. Compared to classical penalization techniques, Bayesian penalization techniques perform similarly or sometimes even better, and they offer additional advantages such as readily available uncertainty estimates, automatic estimation of the penalty parameter, and more flexibility in terms of penalties that can be considered. However, many different shrinkage priors exist and the available, often quite technical, literature primarily focuses on presenting one shrinkage prior and often provides comparisons with only one or two other shrinkage priors. This can make it difficult for researchers to navigate through the many prior options and choose a shrinkage prior for the problem at hand. Therefore, the aim of this paper is to provide a comprehensive overview of the literature on Bayesian penalization. We provide a theoretical and conceptual comparison of nine different shrinkage priors and parametrize the priors, if possible, in terms of scale mixture of normal distributions to facilitate comparisons. We illustrate different characteristics and behaviors of the shrinkage priors and compare their performance in terms of prediction and variable selection in a simulation study. Additionally, we provide two empirical examples to illustrate the application of Bayesian penalization. Finally, an R package bayesreg is available online (https://github.com/sara-vanerp/bayesreg) which allows researchers to perform Bayesian penalized regression with novel shrinkage priors in an easy manner.},
	pages = {31--50},
	journaltitle = {Journal of Mathematical Psychology},
	shortjournal = {Journal of Mathematical Psychology},
	author = {van Erp, Sara and Oberski, Daniel L. and Mulder, Joris},
	urldate = {2024-10-02},
	date = {2019-04-01},
	keywords = {Bayesian, Empirical Bayes, Penalization, Regression, Shrinkage priors},
	file = {Full Text:C\:\\Users\\wzp\\Zotero\\storage\\8WH8TLKD\\van Erp et al. - 2019 - Shrinkage priors for Bayesian penalized regression.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\wzp\\Zotero\\storage\\72DNPF7I\\S0022249618300567.html:text/html},
}


@article{ishwaranSpikeSlabVariable2005,
	title = {Spike and Slab Variable Selection: Frequentist and Bayesian Strategies},
	volume = {33},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/3448605},
	shorttitle = {Spike and Slab Variable Selection},
	abstract = {Variable selection in the linear regression model takes many apparent faces from both frequentist and Bayesian standpoints. In this paper we introduce a variable selection method referred to as a rescaled spike and slab model. We study the importance of prior hierarchical specifications and draw connections to frequentist generalized ridge regression estimation. Specifically, we study the usefulness of continuous bimodal priors to model hypervariance parameters, and the effect scaling has on the posterior mean through its relationship to penalization. Several model selection strategies, some frequentist and some Bayesian in nature, are developed and studied theoretically. We demonstrate the importance of selective shrinkage for effective variable selection in terms of risk misclassification, and show this is achieved using the posterior from a rescaled spike and slab model. We also show how to verify a procedure's ability to reduce model uncertainty in finite samples using a specialized forward selection strategy. Using this tool, we illustrate the effectiveness of rescaled spike and slab models in reducing model uncertainty.},
	pages = {730--773},
	number = {2},
	journaltitle = {The Annals of Statistics},
	author = {Ishwaran, Hemant and Rao, J. Sunil},
	urldate = {2024-10-01},
	date = {2005},
	note = {Publisher: Institute of Mathematical Statistics},
	file = {JSTOR Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\PQB8LPLL\\Ishwaran and Rao - 2005 - Spike and Slab Variable Selection Frequentist and Bayesian Strategies.pdf:application/pdf},
}


@article{vanderpasHorseshoeEstimatorPosterior2014,
	title = {The Horseshoe Estimator: Posterior Concentration around Nearly Black Vectors},
	volume = {8},
	issn = {1935-7524},
	url = {http://arxiv.org/abs/1404.0202},
	doi = {10.1214/14-EJS962},
	shorttitle = {The Horseshoe Estimator},
	abstract = {We consider the horseshoe estimator due to Carvalho, Polson and Scott (2010) for the multivariate normal mean model in the situation that the mean vector is sparse in the nearly black sense. We assume the frequentist framework where the data is generated according to a fixed mean vector. We show that if the number of nonzero parameters of the mean vector is known, the horseshoe estimator attains the minimax \${\textbackslash}ell\_2\$ risk, possibly up to a multiplicative constant. We provide conditions under which the horseshoe estimator combined with an empirical Bayes estimate of the number of nonzero means still yields the minimax risk. We furthermore prove an upper bound on the rate of contraction of the posterior distribution around the horseshoe estimator, and a lower bound on the posterior variance. These bounds indicate that the posterior distribution of the horseshoe prior may be more informative than that of other one-component priors, including the Lasso.},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	shortjournal = {Electron. J. Statist.},
	author = {van der Pas, S. L. and Kleijn, B. J. K. and van der Vaart, A. W.},
	urldate = {2024-12-15},
	date = {2014-01-01},
	eprinttype = {arxiv},
	eprint = {1404.0202 [math, stat]},
	keywords = {62F15, 62F10, Mathematics - Statistics Theory},
	file = {arXiv Fulltext PDF:C\:\\Users\\wzp\\Zotero\\storage\\KFUFZ8IJ\\van der Pas et al. - 2014 - The Horseshoe Estimator Posterior Concentration around Nearly Black Vectors.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\wzp\\Zotero\\storage\\VS2V9GPQ\\1404.html:text/html},
}




@article{piironenSparsityInformationRegularization2017,
	title = {Sparsity information and regularization in the horseshoe and other shrinkage priors},
	volume = {11},
	issn = {1935-7524},
	url = {http://arxiv.org/abs/1707.01694},
	doi = {10.1214/17-EJS1337SI},
	abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	shortjournal = {Electron. J. Statist.},
	author = {Piironen, Juho and Vehtari, Aki},
	urldate = {2024-12-15},
	date = {2017-01-01},
	eprinttype = {arxiv},
	eprint = {1707.01694 [stat]},
	keywords = {Statistics - Methodology},
	file = {arXiv Fulltext PDF:C\:\\Users\\wzp\\Zotero\\storage\\R5YPE5UU\\Piironen and Vehtari - 2017 - Sparsity information and regularization in the horseshoe and other shrinkage priors.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\wzp\\Zotero\\storage\\TT5589ZM\\1707.html:text/html},
}


@article{bainterComparingBayesianVariable2023,
	title = {Comparing Bayesian Variable Selection to Lasso Approaches for Applications in Psychology},
	volume = {88},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/s11336-023-09914-9},
	doi = {10.1007/s11336-023-09914-9},
	abstract = {In the current paper, we review existing tools for solving variable selection problems in psychology. Modern regularization methods such as lasso regression have recently been introduced in the field and are incorporated into popular methodologies, such as network analysis. However, several recognized limitations of lasso regularization may limit its suitability for psychological research. In this paper, we compare the properties of lasso approaches used for variable selection to Bayesian variable selection approaches. In particular we highlight advantages of stochastic search variable selection ({SSVS}), that make it well suited for variable selection applications in psychology. We demonstrate these advantages and contrast {SSVS} with lasso type penalization in an application to predict depression symptoms in a large sample and an accompanying simulation study. We investigate the effects of sample size, effect size, and patterns of correlation among predictors on rates of correct and false inclusion and bias in the estimates. {SSVS} as investigated here is reasonably computationally efficient and powerful to detect moderate effects in small sample sizes (or small effects in moderate sample sizes), while protecting against false inclusion and without over-penalizing true effects. We recommend {SSVS} as a flexible framework that is well-suited for the field, discuss limitations, and suggest directions for future development.},
	pages = {1032--1055},
	number = {3},
	journaltitle = {Psychometrika},
	shortjournal = {Psychometrika},
	author = {Bainter, Sierra A. and {McCauley}, Thomas G. and Fahmy, Mahmoud M. and Goodman, Zachary T. and Kupis, Lauren B. and Rao, J. Sunil},
	urldate = {2024-10-01},
	date = {2023-09-01},
	langid = {english},
	keywords = {Bayesian, lasso, penalization, regression, shrinkage priors, stochastic search variable selection, variable selection},
	file = {Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\DKL46MVX\\Bainter et al. - 2023 - Comparing Bayesian Variable Selection to Lasso Approaches for Applications in Psychology.pdf:application/pdf},
}

@Manual{SSVSpackage,
    title = {SSVS: Functions for Stochastic Search Variable Selection
      (SSVS)},
    author = {Bainter, Sierra A and Thomas McCauley and Mahmoud Fahmy and
      Dean Attali},
    year = {2024},
    note = {R package version 2.0.0},
    url = {https://github.com/sabainter/ssvs},
  }

@Article{brms2017,
    title = {{brms}: An {R} Package for {Bayesian} Multilevel Models
      Using {Stan}},
    author = {Paul-Christian Bürkner},
    journal = {Journal of Statistical Software},
    year = {2017},
    volume = {80},
    number = {1},
    pages = {1--28},
    doi = {10.18637/jss.v080.i01},
    encoding = {UTF-8},
  }
@Article{brms2018,
    title = {Advanced {Bayesian} Multilevel Modeling with the {R}
      Package {brms}},
    author = {Paul-Christian Bürkner},
    journal = {The R Journal},
    year = {2018},
    volume = {10},
    number = {1},
    pages = {395--411},
    doi = {10.32614/RJ-2018-017},
    encoding = {UTF-8},
  }
@Article{brms2021,
    title = {Bayesian Item Response Modeling in {R} with {brms} and
      {Stan}},
    author = {Paul-Christian Bürkner},
    journal = {Journal of Statistical Software},
    year = {2021},
    volume = {100},
    number = {5},
    pages = {1--54},
    doi = {10.18637/jss.v100.i05},
    encoding = {UTF-8},
  }

@Misc{Stan,
Author = {{Stan Development Team}},
Title = {Stan Modeling Language Users Guide and Reference Manual, version 2.33},
url ={https://mc-stan.org},
Year = {2023}
}


@misc{mclatchieAdvancesProjectionPredictive2024,
	title = {Advances in projection predictive inference},
	url = {http://arxiv.org/abs/2306.15581},
	doi = {10.48550/arXiv.2306.15581},
	abstract = {The concepts of Bayesian prediction, model comparison, and model selection have developed significantly over the last decade. As a result, the Bayesian community has witnessed a rapid growth in theoretical and applied contributions to building and selecting predictive models. Projection predictive inference in particular has shown promise to this end, finding application across a broad range of fields. It is less prone to over-fitting than na{\textbackslash}"ive selection based purely on cross-validation or information criteria performance metrics, and has been known to out-perform other methods in terms of predictive performance. We survey the core concept and contemporary contributions to projection predictive inference, and present a safe, efficient, and modular workflow for prediction-oriented model selection therein. We also provide an interpretation of the projected posteriors achieved by projection predictive inference in terms of their limitations in causal settings.},
	number = {{arXiv}:2306.15581},
	publisher = {{arXiv}},
	author = {{McLatchie}, Yann and Rögnvaldsson, Sölvi and Weber, Frank and Vehtari, Aki},
	urldate = {2024-10-21},
	date = {2024-08-06},
	eprinttype = {arxiv},
	eprint = {2306.15581 [stat]},
	keywords = {Statistics - Computation, Statistics - Methodology},
	file = {arXiv Fulltext PDF:C\:\\Users\\wzp\\Zotero\\storage\\Y7Z8VIWU\\McLatchie et al. - 2024 - Advances in projection predictive inference.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\wzp\\Zotero\\storage\\PH93IJTP\\2306.html:text/html},
}

@Misc{projpred,
    title = {{{projpred}}: {{Projection}} Predictive Feature
      Selection},
    author = {Juho Piironen and Markus Paasiniemi and Alejandro
      Catalina and Frank Weber and Aki Vehtari},
    year = {2023},
    note = {R package version 2.8.0},
    url = {https://mc-stan.org/projpred/},
    encoding = {UTF-8},
  }


@article{bair2006,
author = {Bair, Eric and Hastie, Trevor and Paul, Debashis and Tibshirani, Robert},
year = {2006},
month = {02},
pages = {119-137},
title = {Prediction by Supervised Principal Components},
volume = {101},
journal = {Journal of the American Statistical Association},
doi = {10.1198/016214505000000628}
}


@article{goutisModelChoiceGeneralised1998,
	title = {Model choice in generalised linear models: A Bayesian approach via Kullback-Leibler projections},
	volume = {85},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/85.1.29},
	doi = {10.1093/biomet/85.1.29},
	shorttitle = {Model choice in generalised linear models},
	abstract = {We propose a general Bayesian method of comparing models. The approach is based on the Kullback-Leibler distance between two families of models, one nested within the other. For each parameter value of a full model, we compute the projection of the model to the restricted parameter space and the corresponding minimum distance. From the posterior distribution of the minimum distance, we can judge whether or not a more parsimonious model is appropriate. We show how the projection method can be implemented for generalised linear model selection and we propose some Markov chain Monte Carlo algorithms for its practical implementation in less tractable cases. We illustrate the method with examples.},
	pages = {29--37},
	number = {1},
	journaltitle = {Biometrika},
	shortjournal = {Biometrika},
	author = {{Goutis}, {CONSTANTINOS} and {Robert}, {CHRISTIAN} P.},
	urldate = {2024-10-13},
	date = {1998-03-01},
	file = {Snapshot:C\:\\Users\\wzp\\Zotero\\storage\\8H572WVK\\238940.html:text/html},
}

@article{Dupuis2003,
author = {Dupuis, Jérôme and Robert, Christian},
year = {2003},
month = {02},
pages = {77-94},
title = {Variable selection in qualitative models via an entropic explanatory power},
volume = {111},
journal = {Journal of Statistical Planning and Inference},
doi = {10.1016/S0378-3758(02)00286-0}
}


@article{tranPredictiveLasso2012,
	title = {The predictive Lasso},
	volume = {22},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-011-9279-3},
	doi = {10.1007/s11222-011-9279-3},
	abstract = {We propose a shrinkage procedure for simultaneous variable selection and estimation in generalized linear models ({GLMs}) with an explicit predictive motivation. The procedure estimates the coefficients by minimizing the Kullback-Leibler divergence of a set of predictive distributions to the corresponding predictive distributions for the full model, subject to an l1 constraint on the coefficient vector. This results in selection of a parsimonious model with similar predictive performance to the full model. Thanks to its similar form to the original Lasso problem for {GLMs}, our procedure can benefit from available l1-regularization path algorithms. Simulation studies and real data examples confirm the efficiency of our method in terms of predictive performance on future observations.},
	pages = {1069--1084},
	number = {5},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Tran, Minh-Ngoc and Nott, David J. and Leng, Chenlei},
	urldate = {2024-12-18},
	date = {2012-09-01},
	langid = {english},
	keywords = {Artificial Intelligence, Generalized linear models, Kullback-Leibler divergence, Lasso, Optimal prediction, Variable selection},
	file = {Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\EAC6TA3L\\Tran et al. - 2012 - The predictive Lasso.pdf:application/pdf},
}


@misc{catalinaLatentSpaceProjection2021,
	title = {Latent space projection predictive inference},
	url = {http://arxiv.org/abs/2109.04702},
	doi = {10.48550/arXiv.2109.04702},
	abstract = {Given a reference model that includes all the available variables, projection predictive inference replaces its posterior with a constrained projection including only a subset of all variables. We extend projection predictive inference to enable computationally efficient variable and structure selection in models outside the exponential family. By adopting a latent space projection predictive perspective we are able to: 1) propose a unified and general framework to do variable selection in complex models while fully honouring the original model structure, 2) properly identify relevant structure and retain posterior uncertainties from the original model, and 3) provide an improved approach also for non-Gaussian models in the exponential family. We demonstrate the superior performance of our approach by thoroughly testing and comparing it against popular variable selection approaches in a wide range of settings, including realistic data sets. Our results show that our approach successfully recovers relevant terms and model structure in complex models, selecting less variables than competing approaches for realistic datasets.},
	number = {{arXiv}:2109.04702},
	publisher = {{arXiv}},
	author = {Catalina, Alejandro and Bürkner, Paul and Vehtari, Aki},
	urldate = {2024-12-18},
	date = {2021-09-10},
	eprinttype = {arxiv},
	eprint = {2109.04702 [stat]},
	keywords = {Statistics - Computation},
	file = {arXiv Fulltext PDF:C\:\\Users\\wzp\\Zotero\\storage\\GZV3DYUY\\Catalina et al. - 2021 - Latent space projection predictive inference.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\wzp\\Zotero\\storage\\2457HSX3\\2109.html:text/html},
}


@article{piironenComparisonBayesianPredictive2017,
	title = {Comparison of Bayesian predictive methods for model selection},
	volume = {27},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-016-9649-y},
	doi = {10.1007/s11222-016-9649-y},
	abstract = {The goal of this paper is to compare several widely used Bayesian model selection methods in practical model selection problems, highlight their differences and give recommendations about the preferred approaches. We focus on the variable subset selection for regression and classification and perform several numerical experiments using both simulated and real world data. The results show that the optimization of a utility estimate such as the cross-validation ({CV}) score is liable to finding overfitted models due to relatively high variance in the utility estimates when the data is scarce. This can also lead to substantial selection induced bias and optimism in the performance evaluation for the selected model. From a predictive viewpoint, best results are obtained by accounting for model uncertainty by forming the full encompassing model, such as the Bayesian model averaging solution over the candidate models. If the encompassing model is too complex, it can be robustly simplified by the projection method, in which the information of the full model is projected onto the submodels. This approach is substantially less prone to overfitting than selection based on {CV}-score. Overall, the projection method appears to outperform also the maximum a posteriori model and the selection of the most probable variables. The study also demonstrates that the model selection can greatly benefit from using cross-validation outside the searching process both for guiding the model size selection and assessing the predictive performance of the finally selected model.},
	pages = {711--735},
	number = {3},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Piironen, Juho and Vehtari, Aki},
	urldate = {2024-10-01},
	date = {2017-05-01},
	langid = {english},
	keywords = {Artificial Intelligence, Bayesian model selection, Cross-validation, Projection, Reference model, Selection bias},
	file = {Full Text PDF:C\:\\Users\\wzp\\Zotero\\storage\\PIRF4HQ8\\Piironen and Vehtari - 2017 - Comparison of Bayesian predictive methods for model selection.pdf:application/pdf},
}


@article{weberProjectionPredictiveVariable2024,
	title = {Projection predictive variable selection for discrete response families with finite support},
	issn = {1613-9658},
	url = {https://doi.org/10.1007/s00180-024-01506-0},
	doi = {10.1007/s00180-024-01506-0},
	abstract = {The projection predictive variable selection is a decision-theoretically justified Bayesian variable selection approach achieving an outstanding trade-off between predictive performance and sparsity. Its projection problem is not easy to solve in general because it is based on the Kullback–Leibler divergence from a restricted posterior predictive distribution of the so-called reference model to the parameter-conditional predictive distribution of a candidate model. Previous work showed how this projection problem can be solved for response families employed in generalized linear models and how an approximate latent-space approach can be used for many other response families. Here, we present an exact projection method for all response families with discrete and finite support, called the augmented-data projection. A simulation study for an ordinal response family shows that the proposed method performs better than or similarly to the previously proposed approximate latent-space projection. The cost of the slightly better performance of the augmented-data projection is a substantial increase in runtime. Thus, if the augmented-data projection’s runtime is too high, we recommend the latent projection in the early phase of the model-building workflow and the augmented-data projection for final results. The ordinal response family from our simulation study is supported by both projection methods, but we also include a real-world cancer subtyping example with a nominal response family, a case that is not supported by the latent projection.},
	journaltitle = {Computational Statistics},
	shortjournal = {Comput Stat},
	author = {Weber, Frank and Glass, Änne and Vehtari, Aki},
	urldate = {2024-12-18},
	date = {2024-05-29},
	langid = {english},
	keywords = {Bayesian, Nominal, Ordinal, Post-selection inference, Variable selection},
}


@misc{sivulaUncertaintyBayesianLeaveOneOut2023,
	title = {Uncertainty in Bayesian Leave-One-Out Cross-Validation Based Model Comparison},
	url = {http://arxiv.org/abs/2008.10296},
	doi = {10.48550/arXiv.2008.10296},
	abstract = {Leave-one-out cross-validation ({LOO}-{CV}) is a popular method for comparing Bayesian models based on their estimated predictive performance on new, unseen, data. As leave-one-out cross-validation is based on finite observed data, there is uncertainty about the expected predictive performance on new data. By modeling this uncertainty when comparing two models, we can compute the probability that one model has a better predictive performance than the other. Modeling this uncertainty well is not trivial, and for example, it is known that the commonly used standard error estimate is often too small. We study the properties of the Bayesian {LOO}-{CV} estimator and the related uncertainty estimates when comparing two models. We provide new results of the properties both theoretically in the linear regression case and empirically for multiple different models and discuss the challenges of modeling the uncertainty. We show that problematic cases include: comparing models with similar predictions, misspecified models, and small data. In these cases, there is a weak connection in the skewness of the individual leave-one-out terms and the distribution of the error of the Bayesian {LOO}-{CV} estimator. We show that it is possible that the problematic skewness of the error distribution, which occurs when the models make similar predictions, does not fade away when the data size grows to infinity in certain situations. Based on the results, we also provide practical recommendations for the users of Bayesian {LOO}-{CV} for model comparison.},
	number = {{arXiv}:2008.10296},
	publisher = {{arXiv}},
	author = {Sivula, Tuomas and Magnusson, Måns and Matamoros, Asael Alonzo and Vehtari, Aki},
	urldate = {2024-12-18},
	date = {2023-10-21},
	eprinttype = {arxiv},
	eprint = {2008.10296 [stat]},
	keywords = {Statistics - Methodology},
	file = {arXiv Fulltext PDF:C\:\\Users\\wzp\\Zotero\\storage\\TI33F5WN\\Sivula et al. - 2023 - Uncertainty in Bayesian Leave-One-Out Cross-Validation Based Model Comparison.pdf:application/pdf},
}
