---
title: "summAndplot_try"
author: "Zhipei Wang"
date: "2024-12-08"
output: html_document
---
# ppvs
```{r}
# compute_rates <- function(df_out, true_predictors, heuristic_columns) {
#   # Exclude the intercept row
#   df_out <- df_out[rownames(df_out) != "Intercept", , drop = FALSE]
#   
#   # Initialize a named vector to store all rates
#   rates_vector <- c()
#   
#   for (heuristic in heuristic_columns) {
#     if (all(is.na(df_out[[heuristic]]))) {
#       # Assign NA to all rates for this heuristic
#       rates <- c(
#         true_inclusion = NA,
#         false_inclusion = NA,
#         true_exclusion = NA,
#         false_exclusion = NA
#       )
#     } else {
#       # Get selected predictors
#       selected_predictors <- rownames(df_out)[df_out[[heuristic]] == 1]
#       
#       # Compute rates
#       true_inclusion <- sum(selected_predictors %in% true_predictors) / length(true_predictors)
#       false_inclusion <- sum(!(selected_predictors %in% true_predictors)) / (nrow(df_out) - length(true_predictors))
#       false_exclusion <- sum(!(true_predictors %in% selected_predictors)) / length(true_predictors)
#       true_exclusion <- {irrelevant_predictors <- rownames(df_out)[!(rownames(df_out) %in% true_predictors)]
#       excluded_irrelevant_predictors <- irrelevant_predictors[!(irrelevant_predictors %in% selected_predictors)]
#       length(excluded_irrelevant_predictors) / length(irrelevant_predictors)
#       }
# 
#       
#       rates <- c(
#         true_inclusion = true_inclusion,
#         false_inclusion = false_inclusion,
#         true_exclusion = true_exclusion,
#         false_exclusion = false_exclusion
#       )
#     }
#     # Prefix rate names with the heuristic
#     names(rates) <- paste(heuristic, names(rates), sep = "_")
#     # Combine rates into the rates_vector
#     rates_vector <- c(rates_vector, rates)
#   }
#   
#   # Convert rates_vector to a data frame with one row
#   rates_df <- as.data.frame(t(rates_vector), stringsAsFactors = FALSE)
#   return(rates_df)
# }

compute_rates <- function(df_out, true_predictors, heuristic) {
  # Exclude the intercept row
  df_out <- df_out[rownames(df_out) != "Intercept", , drop = FALSE]
  
  if (all(is.na(df_out[[heuristic]]))) {
    print("Suggest_size failed for this heuristic")
    
    # Return NA-filled results instead of failing
    return(list(
      confusion_matrix = matrix(NA, nrow = 2, ncol = 2,
                                dimnames = list("Actual" = c("Non-zero", "Zero"),
                                                "Predicted" = c("Included", "Excluded"))),
      true_inclusion_rate = NA,
      false_inclusion_rate = NA,
      true_exclusion_rate = NA,
      false_exclusion_rate = NA
    ))
  } 

  selected_predictors <- rownames(df_out)[df_out[[heuristic]] == 1]
  
  # Compute inclusion and exclusion counts
  true_inclusion <- sum(selected_predictors %in% true_predictors)
  false_inclusion <- sum(!(selected_predictors %in% true_predictors))
  false_exclusion <- sum(!(true_predictors %in% selected_predictors))
  true_exclusion <- sum(!(rownames(df_out) %in% selected_predictors) & !(rownames(df_out) %in% true_predictors))

  # Compute rates
  true_inclusion_rate <- true_inclusion / length(true_predictors)
  false_inclusion_rate <- false_inclusion / (nrow(df_out) - length(true_predictors))
  false_exclusion_rate <- false_exclusion / length(true_predictors)
  true_exclusion_rate <- true_exclusion / (nrow(df_out) - length(true_predictors))

  # Construct the confusion matrix
  confusion_matrix <- matrix(
    c(true_inclusion, false_exclusion, false_inclusion, true_exclusion),
    nrow = 2,
    byrow = TRUE,
    dimnames = list("Actual" = c("Non-zero", "Zero"), "Predicted" = c("Included", "Excluded"))
  )
  
  return(list(
    confusion_matrix = confusion_matrix,
    true_inclusion_rate = true_inclusion_rate,
    false_inclusion_rate = false_inclusion_rate,
    true_exclusion_rate = true_exclusion_rate,
    false_exclusion_rate = false_exclusion_rate
  ))
}

```



## loc_TE = "first10"
```{r}
# List all files in the df_out folder
df_out_files <- list.files("output_study2/ppvs/df_out/", full.names = TRUE, pattern = "\\.RData$")

# Filter files with loc_TE = "first10"
files_first15 <- df_out_files[grepl("_N50_corr0.2_TEclustered_", df_out_files)]

# the true predictors for first10
true_predictors <- paste0("X", 1:15)

# Compute final results
final_results <- do.call(rbind, lapply(files_first15, function(file_path) {
  load(file_path)
  # Process df_out and compute rates
  heuristic_columns <- grep("^selected_pred_ppvs_", colnames(df_out), value = TRUE)
  rates <- compute_rates(df_out, true_predictors, heuristic_columns)
  
  # Extract conditions from the filename
  conditions <- str_match(file_path, "df_out_N(\\d+)_corr([\\d\\.]+)_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 1]),
    corr = as.numeric(conditions[, 2]),
    TE = conditions[, 3],
    r = as.numeric(conditions[, 4])
  )
  
  # Combine conditions with rates
  cbind(condition_df, rates)
}))

# Rename columns to remove "selected_pred_ppvs_" prefix
colnames(final_results) <- gsub("^selected_pred_ppvs_", "", colnames(final_results))


# View updated results
head(final_results)

```

```{r}
colSums(is.na(final_results))
```



```{r}
# Identify heuristic columns for the rates
heuristic_rate_columns <- grep("_true_inclusion|false_inclusion|true_exclusion|false_exclusion$", 
                               colnames(final_results), value = TRUE)

# Extract unique heuristic prefixes (e.g., "default", "lower", "thres_upper", "thres_lower")
heuristic_prefixes <- unique(gsub("_(true_inclusion|false_inclusion|true_exclusion|false_exclusion)$", "", 
                                  heuristic_rate_columns))

# Compute the means for each heuristic
mean_table_list <- lapply(heuristic_prefixes, function(prefix) {
  cols <- grep(paste0("^", prefix, "_"), heuristic_rate_columns, value = TRUE)
  colMeans(final_results[, cols, drop = FALSE], na.rm = TRUE)
})

# Combine the list into a matrix
mean_table <- do.call(cbind, mean_table_list)

# Assign proper row and column names
rownames(mean_table) <- c("True Inclusion", "False Inclusion", "True Exclusion", "False Exclusion")
colnames(mean_table) <- heuristic_prefixes

# Print the mean table
mean_table <- round(mean_table, 4)
print(mean_table)


```


## loc_TE = "mixed"

```{r}
# List all files in the df_out folder
df_out_files <- list.files("output/df_out/", full.names = TRUE, pattern = "\\.RData$")

# Filter files with loc_TE = "mixed"
files_mixed <- df_out_files[grepl("_loc_TEmixed_", df_out_files)]

# the true predictors for mixed
true_predictors_mixed <- paste0("X", seq(1, 50, 5))

# Compute final results
final_results_mixed <- do.call(rbind, lapply(files_mixed, function(file_path) {
  load(file_path)
  # Process df_out and compute rates
  heuristic_columns <- grep("^selected_pred_ppvs_", colnames(df_out), value = TRUE)
  rates <- compute_rates(df_out, true_predictors_mixed, heuristic_columns)
  
  # Extract conditions from the filename
  conditions <- str_match(file_path, "df_out_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )
  
  # Combine conditions with rates
  cbind(condition_df, rates)
}))

# Rename columns to remove "selected_pred_ppvs_" prefix
colnames(final_results_mixed) <- gsub("^selected_pred_ppvs_", "", colnames(final_results_mixed))


# View updated results
head(final_results_mixed)
```

```{r}
colSums(is.na(final_results_mixed))
```

```{r}
# Identify heuristic columns for the rates
heuristic_rate_columns_mixed <- grep("_true_inclusion|false_inclusion|true_exclusion|false_exclusion$", 
                               colnames(final_results), value = TRUE)

# Extract unique heuristic prefixes (e.g., "default", "lower", "thres_upper", "thres_lower")
heuristic_prefixes <- unique(gsub("_(true_inclusion|false_inclusion|true_exclusion|false_exclusion)$", "", 
                                  heuristic_rate_columns))

# Compute the means for each heuristic
mean_table_list_mixed <- lapply(heuristic_prefixes, function(prefix) {
  cols <- grep(paste0("^", prefix, "_"), heuristic_rate_columns, value = TRUE)
  colMeans(final_results_mixed[, cols, drop = FALSE], na.rm = TRUE)
})

# Combine the list into a matrix
mean_table_mixed <- do.call(cbind, mean_table_list_mixed)

# Assign proper row and column names
rownames(mean_table_mixed) <- c("True Inclusion", "False Inclusion", "True Exclusion", "False Exclusion")
colnames(mean_table_mixed) <- heuristic_prefixes

# Print the mean table
mean_table_mixed <- round(mean_table_mixed, 4)
print(mean_table_mixed)

```


### ppvs by category
```{r}
# Process all PPVS files and compute rates
final_results_ppvs_cat <- do.call(rbind, lapply(files_first10, function(file) {
  load(file) # Load the df_out object

  # Remove the intercept row
  df_out <- df_out[rownames(df_out) != "Intercept", ]

  # Initialize a list to store rates for each effect size
  rates <- lapply(names(effect_size_groups), function(group) {
    predictors <- effect_size_groups[[group]]
    
    # Compute inclusion rates for all heuristics
    inclusion_rates <- sapply(heuristic_columns, function(heuristic) {
      selected <- df_out[[heuristic]][rownames(df_out) %in% predictors]
      
      # Check if the column is entirely NA
      if (all(is.na(df_out[[heuristic]]))) {
        return(NA)  # Entirely NA column; return NA
      }
      
      # Compute inclusion rate
      inclusion_rate <- sum(selected) / length(predictors)
      return(inclusion_rate)
    })
    
    # Return a data frame for the current effect size
    data.frame(
      effect_size = group,
      t(inclusion_rates)
    )
  })
  
  # Combine all effect size rates into a single data frame
  rates_df <- do.call(rbind, rates)

  # Extract conditions from the filename
  conditions <- str_match(file, "df_out_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )
  
  # Combine conditions with rates
  cbind(condition_df, rates_df)
}))

print(final_results_ppvs_cat)
```

```{r}
mean_rates_ppvs_cat <- aggregate(
  . ~ effect_size,
  data = final_results_ppvs_cat[, -c(1:4)],
  mean,
  na.rm = TRUE
)
# Round all numeric columns to 4 decimal places
mean_rates_ppvs_cat[, -1] <- round(mean_rates_ppvs_cat[, -1], 4)
print(mean_rates_ppvs_cat)
```


```{r}
# Process all PPVS files and compute rates
final_results_ppvs_cat_uncorrTE <- do.call(rbind, lapply(files_mixed, function(file) {
  load(file) # Load the df_out object

  # Remove the intercept row
  df_out <- df_out[rownames(df_out) != "Intercept", ]

  # Initialize a list to store rates for each effect size
  rates <- lapply(names(effect_size_groups_uncorrTE), function(group) {
    predictors <- effect_size_groups_uncorrTE[[group]]
    
    # Compute inclusion rates for all heuristics
    inclusion_rates <- sapply(heuristic_columns, function(heuristic) {
      selected <- df_out[[heuristic]][rownames(df_out) %in% predictors]
      
      # Check if the column is entirely NA
      if (all(is.na(df_out[[heuristic]]))) {
        return(NA)  # Entirely NA column; return NA
      }
      
      # Compute inclusion rate
      inclusion_rate <- sum(selected) / length(predictors)
      return(inclusion_rate)
    })
    
    # Return a data frame for the current effect size
    data.frame(
      effect_size = group,
      t(inclusion_rates)
    )
  })
  
  # Combine all effect size rates into a single data frame
  rates_df <- do.call(rbind, rates)

  # Extract conditions from the filename
  conditions <- str_match(file, "df_out_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )
  
  # Combine conditions with rates
  cbind(condition_df, rates_df)
}))

print(final_results_ppvs_cat_uncorrTE)
```

```{r}
mean_rates_ppvs_cat_uncorrTE <- aggregate(
  . ~ effect_size,
  data = final_results_ppvs_cat_uncorrTE[, -c(1:4)],
  mean,
  na.rm = TRUE
)
# Round all numeric columns to 4 decimal places
mean_rates_ppvs_cat_uncorrTE[, -1] <- round(mean_rates_ppvs_cat_uncorrTE[, -1], 4)
print(mean_rates_ppvs_cat_uncorrTE)
```
# ssvs

## loc_TE = "first10"
```{r}
compute_ssvs_rates <- function(ssvs_df_out, true_predictors) {
  selected_predictors <- ssvs_df_out$Variable[ssvs_df_out$selected_pred_ssvs == 1]
  
  # Calculate inclusion and exclusion counts
  true_inclusion <- sum(selected_predictors %in% true_predictors)
  false_inclusion <- sum(!(selected_predictors %in% true_predictors))
  false_exclusion <- sum(!(true_predictors %in% selected_predictors))
  true_exclusion <- sum(!(ssvs_df_out$Variable %in% selected_predictors) & !(ssvs_df_out$Variable %in% true_predictors))
  
  # Calculate rates
  true_inclusion_rate <- true_inclusion / length(true_predictors)
  false_inclusion_rate <- false_inclusion / (nrow(ssvs_df_out) - length(true_predictors))
  false_exclusion_rate <- false_exclusion / length(true_predictors)
  true_exclusion_rate <- true_exclusion / (nrow(ssvs_df_out) - length(true_predictors))
  
  # Construct the confusion matrix
  confusion_matrix <- matrix(
    c(true_inclusion, false_exclusion, false_inclusion, true_exclusion),
    nrow = 2,
    byrow = TRUE,
    dimnames = list("Actual" = c("Non-zero", "Zero"), "Predicted" = c("Included", "Excluded"))
  )
  
  # Print rates
  cat("\nTrue Inclusion Rate:", round(true_inclusion_rate, 3))
  cat("\nFalse Inclusion Rate:", round(false_inclusion_rate, 3))
  cat("\nTrue Exclusion Rate:", round(true_exclusion_rate, 3))
  cat("\nFalse Exclusion Rate:", round(false_exclusion_rate, 3), "\n")

  return(list(
    confusion_matrix = confusion_matrix,
    true_inclusion_rate = true_inclusion_rate,
    false_inclusion_rate = false_inclusion_rate,
    true_exclusion_rate = true_exclusion_rate,
    false_exclusion_rate = false_exclusion_rate
  ))
}

```

```{r}
# List all SSVS files
ssvs_files <- list.files("output/ssvs_df_out/", full.names = TRUE, pattern = "\\.RData$")

# Filter files with loc_TE = "first10"
ssvs_files_first10 <- ssvs_files[grepl("_loc_TEfirst10_", ssvs_files)]

# Define true predictors
true_predictors <- paste0("X", 1:10)

# Compute final results
final_results_ssvs <- do.call(rbind, lapply(ssvs_files_first10, function(file_path) {
  load(file_path)  # Load the file; assumes it contains `ssvs_df_out`
  
  # Compute rates for SSVS
  rates <- compute_ssvs_rates(ssvs_df_out, true_predictors)
  rates <- as.data.frame(t(rates)) 
  
  # Extract conditions from the filename
  conditions <- str_match(file_path, "ssvs_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )
  
  # Combine conditions with rates
  cbind(condition_df, rates)
}))

# View final results
head(final_results_ssvs)

```

```{r}
mean_rates_ssvs <- sapply(final_results_ssvs[, 5:8], mean)
mean_rates_table_ssvs <- as.data.frame(t(mean_rates_ssvs))
colnames(mean_rates_table_ssvs) <- c("True Inclusion", "False Inclusion", "True Exclusion", "False Exclusion")

# Print mean rates
print(mean_rates_table_ssvs)
```

## loc_TE = "mixed"
```{r}
# Filter files with loc_TE = "mixed"
ssvs_files_mixed <- ssvs_files[grepl("_loc_TEmixed_", ssvs_files)]

# Define true predictors
true_predictors_mixed <- paste0("X", seq(1, 50, 5))

# Compute final results
final_results_ssvs_mixed <- do.call(rbind, lapply(ssvs_files_mixed, function(file_path) {
  load(file_path)  # Load the file; assumes it contains `ssvs_df_out`
  
  # Compute rates for SSVS
  rates <- compute_ssvs_rates(ssvs_df_out, true_predictors_mixed)
  rates <- as.data.frame(t(rates)) 
  
  # Extract conditions from the filename
  conditions <- str_match(file_path, "ssvs_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )
  
  # Combine conditions with rates
  cbind(condition_df, rates)
}))

# View final results
head(final_results_ssvs_mixed)
```

```{r}
mean_rates_ssvs_mixed <- sapply(final_results_ssvs_mixed[, 5:8], mean)
mean_rates_table_ssvs_mixed <- as.data.frame(t(mean_rates_ssvs_mixed))
colnames(mean_rates_table_ssvs_mixed) <- c("True Inclusion", "False Inclusion", "True Exclusion", "False Exclusion")

# Print mean rates
print(mean_rates_table_ssvs_mixed)
```

### ssvs by category
#### loc_TE = "first10"
```{r}
# Define effect size categories
effect_size_groups <- list(
  large_effect = c("X1", "X6"),
  medium_effect = c("X2", "X3", "X7", "X8"),
  small_effect = c("X4", "X5", "X9", "X10"),
  null_effect = paste0("X", 11:50)
)


# Initialize an empty list to store results
final_results_ssvs_cat <- do.call(rbind, lapply(ssvs_files_first10, function(file) {
  load(file) # Load the ssvs_df_out object

  # Compute inclusion rates for each effect size
  rates <- lapply(names(effect_size_groups), function(group) {
    predictors <- effect_size_groups[[group]]
    selected <- ssvs_df_out$selected_pred_ssvs[ssvs_df_out$Variable %in% predictors]
    
    inclusion_rate <- sum(selected) / length(predictors)
    
    data.frame(
      effect_size = group,
      inclusion_rate = inclusion_rate
    )
  })
  
  rates_df <- do.call(rbind, rates)

  # Extract conditions from the filename
  conditions <- str_match(file, "ssvs_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )

  # Combine rates and conditions
  rates_df <- cbind(condition_df, rates_df)
  return(rates_df)
}))

print(final_results_ssvs_cat)
```


```{r}
# Compute mean inclusion rates for each effect size
mean_rates_ssvs_cat <- aggregate(
  inclusion_rate ~ effect_size, 
  data = final_results_ssvs_cat, 
  mean
)

# Rename columns for clarity
colnames(mean_rates_ssvs_cat) <- c("Effect Size", "Mean Inclusion Rate")

# View results
print(mean_rates_ssvs_cat)

```


```{r}
# Define effect size categories
effect_size_groups_uncorrTE <- list(
  large_effect = c("X1", "X26"),
  medium_effect = c("X6", "X11", "X31", "X36"),
  small_effect = c("X16", "X21", "X41", "X46"),
  null_effect = setdiff(paste0("X", 1:50), c("X1", "X6", "X11", "X16", "X21", "26", "X31", "X36", "X41", "X46"))
)


# Initialize an empty list to store results
final_results_ssvs_cat_uncorrTE <- do.call(rbind, lapply(ssvs_files_mixed, function(file) {
  load(file) # Load the ssvs_df_out object

  # Compute inclusion rates for each effect size
  rates <- lapply(names(effect_size_groups_uncorrTE), function(group) {
    predictors <- effect_size_groups_uncorrTE[[group]]
    selected <- ssvs_df_out$selected_pred_ssvs[ssvs_df_out$Variable %in% predictors]
    
    inclusion_rate <- sum(selected) / length(predictors)
    
    data.frame(
      effect_size = group,
      inclusion_rate = inclusion_rate
    )
  })
  
  rates_df <- do.call(rbind, rates)

  # Extract conditions from the filename
  conditions <- str_match(file, "ssvs_N(\\d+)_corr([\\d\\.]+)_loc_TE([a-zA-Z0-9]+)_r(\\d+)\\.RData")
  condition_df <- data.frame(
    N = as.numeric(conditions[, 2]),
    corr = as.numeric(conditions[, 3]),
    loc_TE = conditions[, 4],
    r = as.numeric(conditions[, 5])
  )

  # Combine rates and conditions
  rates_df <- cbind(condition_df, rates_df)
  return(rates_df)
}))

print(final_results_ssvs_cat_uncorrTE)
```


```{r}
# Compute mean inclusion rates for each effect size
mean_rates_ssvs_cat_uncorrTE <- aggregate(
  inclusion_rate ~ effect_size, 
  data = final_results_ssvs_cat_uncorrTE, 
  mean
)

# Rename columns for clarity
colnames(mean_rates_ssvs_cat_uncorrTE) <- c("Effect Size", "Mean Inclusion Rate")
mean_rates_ssvs_cat_uncorrTE[, 2] <- round(mean_rates_ssvs_cat_uncorrTE[, 2], 4)

# View results
print(mean_rates_ssvs_cat_uncorrTE)
```


```{r}
# dataframe for correlated true effects
# df_corr <- cbind(mean_rates_ppvs_cat, mean_rates_ssvs_cat[, 2])
# colnames(df_corr) <- c("effect_size", "default", "type_lower", "thres_upper", "thres_lower", "ssvs")
```


```{r}
df_corr <- data.frame(
  effect_size = c("large", "medium", "null", "small"),
  default = c(1.0000, 0.8864, 0.0027, 0.1227),
  type_lower = c(1.0000, 0.9773, 0.0173, 0.2545),
  thres_upper = c(1.0000, 0.8864, 0.0023, 0.1182),
  thres_lower = c(1.0000, 0.8909, 0.0023, 0.1227),
  ssvs = c(1.0000, 0.9825, 0.0075, 0.2775)
)

# Reshape the dataframe
df_corr <- df_corr %>%
  pivot_longer(
    cols = -effect_size, # Exclude effect_size from the reshaping
    names_to = "heuristic", # Column name for heuristics
    values_to = "inclusion_rate" # Column name for rates
  ) %>%
  mutate(
    method = if_else(heuristic == "ssvs", "SSVS", "PPVS") # Create the method column
  )

df_corr$condition <- "correlated"

# Print the reshaped dataframe
print(df_corr)
```

```{r}
df_all <- rbind(df_corr, df_uncorr)
print(df_all)
```


```{r}
ggplot(df_all, aes(x = effect_size, y = inclusion_rate)) +
  geom_point(aes(color = heuristic), size = 3) +
  facet_wrap(~condition, scales = "free_y")
```

```{r}
# df_uncorr <- cbind(mean_rates_ppvs_cat_uncorrTE, mean_rates_ssvs_cat_uncorrTE[, 2])
# colnames(df_uncorr) <- c("effect_size", "default", "type_lower", "thres_upper", "thres_lower", "ssvs")
# df_uncorr
```

```{r}
df_uncorr <- data.frame(
  effect_size = c("large", "medium", "null", "small"),
  default = c(1.0000, 1.0000, 0.0455, 0.2045),
  type_lower = c(1.0000, 1.0000, 0.0732, 0.3068),
  thres_upper = c(1.0000, 1.0000, 0.0443, 0.1705),
  thres_lower = c(1.0000, 1.0000, 0.0455, 0.1705),
  ssvs = c(1.0000, 0.9900, 0.0468, 0.2750)
)

# Reshape the dataframe
df_uncorr <- df_uncorr %>%
  pivot_longer(
    cols = -effect_size, # Exclude effect_size from the reshaping
    names_to = "heuristic", # Column name for heuristics
    values_to = "inclusion_rate" # Column name for rates
  ) %>%
  mutate(
    method = if_else(heuristic == "ssvs", "SSVS", "PPVS") # Create the method column
  )

df_uncorr$condition <- "uncorrelated"
print(df_uncorr)
```

```{r}
ggplot(df_all, aes(x = method, y = inclusion_rate, color = heuristic, shape = condition)) +
  geom_point(size = 3) + 
  facet_wrap(~effect_size, scales = "free_y", ncol = 4) + # Change number of columns based on your preference
  labs(
    title = "Inclusion Rates by Method, Heuristic, and Condition",
    x = "Method",
    y = "Inclusion Rate (%)",
    color = "Heuristic",
    shape = "Condition"
  ) +
  theme_minimal() + # Using a minimal theme
  theme(
    text = element_text(size = 12), # Adjust text size as needed
    legend.position = "bottom", # Moving legend to the bottom
    strip.text.x = element_text(size = 14, face = "bold") # Bold facet labels
  ) +
  scale_color_brewer(palette = "Set1") # Using a color-blind friendly palette

```

```{r}
# Assuming df_all is your data frame and already contains the 'inclusion_rate' values for SSVS
ssvs_data <- df_all %>% 
  filter(method == "SSVS")

# Plotting the data
ggplot(df_all, aes(x = effect_size, y = inclusion_rate)) +
  geom_point(data = filter(df_all, method != "SSVS"), aes(color = heuristic, shape = heuristic), size = 3) +
  facet_wrap(~condition, scales = "free_y") +
  geom_hline(data = ssvs_data, aes(yintercept = inclusion_rate, group = effect_size), color = "black", linetype = "solid", size = 1) +
  scale_color_manual(values = c("default" = "red", "thres_lower" = "blue", "thres_upper" = "green", "type_lower" = "purple")) +
  scale_shape_manual(values = c("default" = 16, "thres_lower" = 17, "thres_upper" = 18, "type_lower" = 19)) +
  labs(
    title = "Inclusion Rates by Method, Heuristic, and Condition",
    x = "Effect Size",
    y = "Inclusion Rate (%)",
    color = "Heuristic"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  )
```



